{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Lab: Building Advanced Transformers**\n",
    "\n",
    "**Estimated time needed:  30 minutes**  \n",
    "\n",
    "In this lab, you will implement and experiment with advanced Transformer models using Keras. \n",
    "\n",
    "**Learning objectives:** \n",
    "\n",
    "By the end of this lab, you will: \n",
    "\n",
    "- Implement advanced Transformer models using Keras. \n",
    "\n",
    "- Apply Transformers to real-world sequential data tasks. \n",
    "\n",
    "- Build, train, and evaluate Transformer models. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-by-Step Instructions: \n",
    "\n",
    "### Step 1: Import necessary libraries \n",
    "\n",
    "Before you start, you need to import the required libraries: TensorFlow and Keras. Keras is included within TensorFlow as `tensorflow.keras.`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-19.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.1.24-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from tensorflow) (24.2)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from tensorflow) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.70.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.8.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting numpy<2.1.0,>=1.26.0 (from tensorflow)\n",
      "  Downloading numpy-2.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.12.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (47 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.18.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.5/615.5 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-19.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (42.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.1.24-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.70.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.12.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.8.0-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.4.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (89 kB)\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (400 kB)\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorboard-data-server, pyarrow, protobuf, optree, opt-einsum, numpy, mdurl, markdown, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, ml-dtypes, markdown-it-py, h5py, rich, keras, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-25.1.24 gast-0.6.0 google-pasta-0.2.0 grpcio-1.70.0 h5py-3.12.1 keras-3.8.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.8 numpy-2.0.2 opt-einsum-3.4.0 optree-0.14.0 protobuf-5.29.3 pyarrow-19.0.0 rich-13.9.4 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 termcolor-2.5.0 werkzeug-3.1.3 wrapt-1.17.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m156.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Installing collected packages: tzdata, pandas\n",
      "Successfully installed pandas-2.2.3 tzdata-2025.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (2.0.2)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m185.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading scipy-1.15.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.2/40.2 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.1 scipy-1.15.1 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.55.6-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (166 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.1.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m121.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (323 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.55.6-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m174.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m106.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-11.1.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m147.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.55.6 kiwisolver-1.4.8 matplotlib-3.10.0 pillow-11.1.0 pyparsing-3.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests) (2024.12.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow pyarrow \n",
    "%pip install pandas  \n",
    "%pip install scikit-learn \n",
    "%pip install matplotlib \n",
    "%pip install requests\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-25 08:34:57.928995: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-25 08:34:57.930137: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-25 08:34:57.933862: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-25 08:34:57.944597: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1737794097.962584     133 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1737794097.968036     133 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-25 08:34:57.987444: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "import requests\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Setup the Environment to generate synthetic stock price data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic stock_prices.csv created and loaded.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create a synthetic stock price dataset\n",
    "np.random.seed(42)\n",
    "data_length = 2000  # Adjust data length as needed\n",
    "trend = np.linspace(100, 200, data_length)\n",
    "noise = np.random.normal(0, 2, data_length)\n",
    "synthetic_data = trend + noise\n",
    "\n",
    "# Create a DataFrame and save as 'stock_prices.csv'\n",
    "data = pd.DataFrame(synthetic_data, columns=['Close'])\n",
    "data.to_csv('stock_prices.csv', index=False)\n",
    "print(\"Synthetic stock_prices.csv created and loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('stock_prices.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.993428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99.773496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101.395427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103.196135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99.731793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>99.781851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>103.458576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>101.885045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>99.461251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>101.535345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>99.573415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>99.618816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>101.084225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>96.823765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>97.250515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>99.625800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>98.774738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>101.478920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>99.084402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>98.125868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Close\n",
       "0   100.993428\n",
       "1    99.773496\n",
       "2   101.395427\n",
       "3   103.196135\n",
       "4    99.731793\n",
       "5    99.781851\n",
       "6   103.458576\n",
       "7   101.885045\n",
       "8    99.461251\n",
       "9   101.535345\n",
       "10   99.573415\n",
       "11   99.618816\n",
       "12  101.084225\n",
       "13   96.823765\n",
       "14   97.250515\n",
       "15   99.625800\n",
       "16   98.774738\n",
       "17  101.478920\n",
       "18   99.084402\n",
       "19   98.125868"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[100.99342831],\n",
       "       [ 99.77349641],\n",
       "       [101.3954271 ],\n",
       "       ...,\n",
       "       [198.13620067],\n",
       "       [199.62384106],\n",
       "       [198.51019471]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['Close']].values\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (1899, 100, 1)\n",
      "Shape of Y: (1899,)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset \n",
    "data = pd.read_csv('stock_prices.csv') \n",
    "data = data[['Close']].values \n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data = scaler.fit_transform(data)\n",
    "\n",
    "# Prepare the data for training\n",
    "def create_dataset(data, time_step=1):\n",
    "    X, Y = [], []\n",
    "\n",
    "    for i in range(len(data)-time_step-1):\n",
    "        a = data[i:(i+time_step), 0]\n",
    "        X.append(a)\n",
    "        Y.append(data[i + time_step, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "time_step = 100\n",
    "X, Y = create_dataset(data, time_step)\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "print(\"Shape of X:\", X.shape) \n",
    "print(\"Shape of Y:\", Y.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.03884152],\n",
       "        [0.02747753],\n",
       "        [0.04258624],\n",
       "        [0.05936031],\n",
       "        [0.02708906],\n",
       "        [0.02755536],\n",
       "        [0.06180502],\n",
       "        [0.04714716],\n",
       "        [0.02456889],\n",
       "        [0.04388962],\n",
       "        [0.02561372],\n",
       "        [0.02603664],\n",
       "        [0.03968731],\n",
       "        [0.        ],\n",
       "        [0.00397529],\n",
       "        [0.0261017 ],\n",
       "        [0.01817383],\n",
       "        [0.043364  ],\n",
       "        [0.02105844],\n",
       "        [0.01212944],\n",
       "        [0.06621321],\n",
       "        [0.03516706],\n",
       "        [0.04109748],\n",
       "        [0.01376157],\n",
       "        [0.03062924],\n",
       "        [0.04330392],\n",
       "        [0.02025975],\n",
       "        [0.04916882],\n",
       "        [0.03144515],\n",
       "        [0.03766695],\n",
       "        [0.03235725],\n",
       "        [0.07854228],\n",
       "        [0.04424789],\n",
       "        [0.02525963],\n",
       "        [0.06075579],\n",
       "        [0.02315238],\n",
       "        [0.05025458],\n",
       "        [0.01031964],\n",
       "        [0.02255052],\n",
       "        [0.05142895],\n",
       "        [0.06198534],\n",
       "        [0.051886  ],\n",
       "        [0.04700473],\n",
       "        [0.04401559],\n",
       "        [0.02254566],\n",
       "        [0.03714622],\n",
       "        [0.04244135],\n",
       "        [0.07118404],\n",
       "        [0.05835708],\n",
       "        [0.01957492],\n",
       "        [0.05892514],\n",
       "        [0.04617899],\n",
       "        [0.04120786],\n",
       "        [0.06568113],\n",
       "        [0.07395934],\n",
       "        [0.07256751],\n",
       "        [0.04004819],\n",
       "        [0.05038847],\n",
       "        [0.06278687],\n",
       "        [0.07525617],\n",
       "        [0.04861998],\n",
       "        [0.05455432],\n",
       "        [0.03786763],\n",
       "        [0.03665927],\n",
       "        [0.07454902],\n",
       "        [0.0851447 ],\n",
       "        [0.05900164],\n",
       "        [0.07950557],\n",
       "        [0.06801269],\n",
       "        [0.04972229],\n",
       "        [0.0689402 ],\n",
       "        [0.09132764],\n",
       "        [0.06247174],\n",
       "        [0.09275534],\n",
       "        [0.01526396],\n",
       "        [0.07984967],\n",
       "        [0.06662492],\n",
       "        [0.05989852],\n",
       "        [0.06764473],\n",
       "        [0.02937171],\n",
       "        [0.06277457],\n",
       "        [0.07398636],\n",
       "        [0.09533311],\n",
       "        [0.05860951],\n",
       "        [0.05366849],\n",
       "        [0.05984915],\n",
       "        [0.08671757],\n",
       "        [0.07625395],\n",
       "        [0.06072543],\n",
       "        [0.08062358],\n",
       "        [0.07333574],\n",
       "        [0.0900395 ],\n",
       "        [0.0593795 ],\n",
       "        [0.0668206 ],\n",
       "        [0.06608594],\n",
       "        [0.04659106],\n",
       "        [0.07983999],\n",
       "        [0.0796527 ],\n",
       "        [0.07535037],\n",
       "        [0.07135062]],\n",
       "\n",
       "       [[0.02747753],\n",
       "        [0.04258624],\n",
       "        [0.05936031],\n",
       "        [0.02708906],\n",
       "        [0.02755536],\n",
       "        [0.06180502],\n",
       "        [0.04714716],\n",
       "        [0.02456889],\n",
       "        [0.04388962],\n",
       "        [0.02561372],\n",
       "        [0.02603664],\n",
       "        [0.03968731],\n",
       "        [0.        ],\n",
       "        [0.00397529],\n",
       "        [0.0261017 ],\n",
       "        [0.01817383],\n",
       "        [0.043364  ],\n",
       "        [0.02105844],\n",
       "        [0.01212944],\n",
       "        [0.06621321],\n",
       "        [0.03516706],\n",
       "        [0.04109748],\n",
       "        [0.01376157],\n",
       "        [0.03062924],\n",
       "        [0.04330392],\n",
       "        [0.02025975],\n",
       "        [0.04916882],\n",
       "        [0.03144515],\n",
       "        [0.03766695],\n",
       "        [0.03235725],\n",
       "        [0.07854228],\n",
       "        [0.04424789],\n",
       "        [0.02525963],\n",
       "        [0.06075579],\n",
       "        [0.02315238],\n",
       "        [0.05025458],\n",
       "        [0.01031964],\n",
       "        [0.02255052],\n",
       "        [0.05142895],\n",
       "        [0.06198534],\n",
       "        [0.051886  ],\n",
       "        [0.04700473],\n",
       "        [0.04401559],\n",
       "        [0.02254566],\n",
       "        [0.03714622],\n",
       "        [0.04244135],\n",
       "        [0.07118404],\n",
       "        [0.05835708],\n",
       "        [0.01957492],\n",
       "        [0.05892514],\n",
       "        [0.04617899],\n",
       "        [0.04120786],\n",
       "        [0.06568113],\n",
       "        [0.07395934],\n",
       "        [0.07256751],\n",
       "        [0.04004819],\n",
       "        [0.05038847],\n",
       "        [0.06278687],\n",
       "        [0.07525617],\n",
       "        [0.04861998],\n",
       "        [0.05455432],\n",
       "        [0.03786763],\n",
       "        [0.03665927],\n",
       "        [0.07454902],\n",
       "        [0.0851447 ],\n",
       "        [0.05900164],\n",
       "        [0.07950557],\n",
       "        [0.06801269],\n",
       "        [0.04972229],\n",
       "        [0.0689402 ],\n",
       "        [0.09132764],\n",
       "        [0.06247174],\n",
       "        [0.09275534],\n",
       "        [0.01526396],\n",
       "        [0.07984967],\n",
       "        [0.06662492],\n",
       "        [0.05989852],\n",
       "        [0.06764473],\n",
       "        [0.02937171],\n",
       "        [0.06277457],\n",
       "        [0.07398636],\n",
       "        [0.09533311],\n",
       "        [0.05860951],\n",
       "        [0.05366849],\n",
       "        [0.05984915],\n",
       "        [0.08671757],\n",
       "        [0.07625395],\n",
       "        [0.06072543],\n",
       "        [0.08062358],\n",
       "        [0.07333574],\n",
       "        [0.0900395 ],\n",
       "        [0.0593795 ],\n",
       "        [0.0668206 ],\n",
       "        [0.06608594],\n",
       "        [0.04659106],\n",
       "        [0.07983999],\n",
       "        [0.0796527 ],\n",
       "        [0.07535037],\n",
       "        [0.07135062],\n",
       "        [0.04981799]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04981799, 0.06881625])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "`tensorflow` is the main library for machine learning in Python.  \n",
    "\n",
    "`stock_prices.csv` is the data set that is loaded. \n",
    "\n",
    "`MinMaxScaler` method is used to normalize the data.  \n",
    "\n",
    "`create_dataset`method is used to prepare the data for training. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Implement Multi-Head Self-Attention \n",
    "\n",
    "Define the Multi-Head Self-Attention mechanism. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads=8): \n",
    "        super(MultiHeadSelfAttention, self).__init__() \n",
    "        self.embed_dim = embed_dim \n",
    "        self.num_heads = num_heads \n",
    "        self.projection_dim = embed_dim // num_heads \n",
    "        self.query_dense = Dense(embed_dim) \n",
    "        self.key_dense = Dense(embed_dim) \n",
    "        self.value_dense = Dense(embed_dim) \n",
    "        self.combine_heads = Dense(embed_dim) \n",
    "\n",
    "\n",
    "    def attention(self, query, key, value): \n",
    "        score = tf.matmul(query, key, transpose_b=True) \n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32) \n",
    "        scaled_score = score / tf.math.sqrt(dim_key) \n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1) \n",
    "        output = tf.matmul(weights, value) \n",
    "        return output, weights \n",
    "\n",
    "    def split_heads(self, x, batch_size): \n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim)) \n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3]) \n",
    "\n",
    "    def call(self, inputs): \n",
    "        batch_size = tf.shape(inputs)[0] \n",
    "        query = self.query_dense(inputs) \n",
    "        key = self.key_dense(inputs) \n",
    "        value = self.value_dense(inputs) \n",
    "        query = self.split_heads(query, batch_size) \n",
    "        key = self.split_heads(key, batch_size) \n",
    "        value = self.split_heads(value, batch_size) \n",
    "        attention, _ = self.attention(query, key, value) \n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3]) \n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim)) \n",
    "        output = self.combine_heads(concat_attention) \n",
    "        return output \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The MultiHeadSelfAttention layer implements the multi-head self-attention mechanism, which allows the model to focus on different parts of the input sequence simultaneously. \n",
    "\n",
    "- The attention parameter computes the attention scores and weighted sum of the values. \n",
    "\n",
    "- The split_heads parameter splits the input into multiple heads for parallel attention computation. \n",
    "\n",
    "- The call method applies the self-attention mechanism and combines the heads. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Implement Transformer block \n",
    "\n",
    "Define the Transformer block. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerBlock, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    "\n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code:\n",
    "\n",
    "- The TransformerBlock layer combines multi-head self-attention with a feed-forward neural network and normalization layers.  \n",
    "\n",
    "- Dropout is used to prevent overfitting. \n",
    "\n",
    "- The call method applies the self-attention, followed by the feedforward network with residual connections and layer normalization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Implement Encoder Layer \n",
    "\n",
    "Define the Encoder layer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(EncoderLayer, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    "\n",
    " \n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The EncoderLayer is similar to the TransformerBlock but is a reusable layer in the Transformer architecture. \n",
    "\n",
    "- It consists of a MultiHeadSelfAttention mechanism followed by a feedforward neural network. \n",
    "\n",
    "- Both sub-layers have residual connections around them, and layer normalization is applied to the output of each sub-layer. \n",
    "\n",
    "- The call method applies the self-attention, followed by the feedforward network, with residual connections and layer normalization. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Implement Transformer encoder \n",
    "\n",
    "Define the Transformer Encoder. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-25 08:50:56.360097: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100, 128)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout \n",
    "\n",
    "class MultiHeadSelfAttention(Layer): \n",
    "    def __init__(self, embed_dim, num_heads=8): \n",
    "        super(MultiHeadSelfAttention, self).__init__() \n",
    "        self.embed_dim = embed_dim \n",
    "        self.num_heads = num_heads \n",
    "        self.projection_dim = embed_dim // num_heads \n",
    "        self.query_dense = Dense(embed_dim) \n",
    "        self.key_dense = Dense(embed_dim) \n",
    "        self.value_dense = Dense(embed_dim) \n",
    "        self.combine_heads = Dense(embed_dim) \n",
    " \n",
    "\n",
    "    def attention(self, query, key, value): \n",
    "        score = tf.matmul(query, key, transpose_b=True) \n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32) \n",
    "        scaled_score = score / tf.math.sqrt(dim_key) \n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1) \n",
    "        output = tf.matmul(weights, value) \n",
    "        return output, weights \n",
    "\n",
    "\n",
    "    def split_heads(self, x, batch_size): \n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim)) \n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3]) \n",
    "\n",
    "\n",
    "    def call(self, inputs): \n",
    "        batch_size = tf.shape(inputs)[0] \n",
    "        query = self.query_dense(inputs) \n",
    "        key = self.key_dense(inputs) \n",
    "        value = self.value_dense(inputs) \n",
    "        query = self.split_heads(query, batch_size) \n",
    "        key = self.split_heads(key, batch_size) \n",
    "        value = self.split_heads(value, batch_size) \n",
    "        attention, _ = self.attention(query, key, value) \n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3]) \n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim)) \n",
    "        output = self.combine_heads(concat_attention) \n",
    "        return output \n",
    "\n",
    "class TransformerBlock(Layer): \n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerBlock, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    " \n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) \n",
    "\n",
    "class TransformerEncoder(Layer): \n",
    "    def __init__(self, num_layers, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerEncoder, self).__init__() \n",
    "        self.num_layers = num_layers \n",
    "        self.embed_dim = embed_dim \n",
    "        self.enc_layers = [TransformerBlock(embed_dim, num_heads, ff_dim, rate) for _ in range(num_layers)] \n",
    "        self.dropout = Dropout(rate) \n",
    "\n",
    "    def call(self, inputs, training=False): \n",
    "        x = inputs \n",
    "        for i in range(self.num_layers): \n",
    "            x = self.enc_layers[i](x, training=training) \n",
    "        return x \n",
    "\n",
    "# Example usage \n",
    "embed_dim = 128 \n",
    "num_heads = 8 \n",
    "ff_dim = 512 \n",
    "num_layers = 4 \n",
    "\n",
    "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim) \n",
    "inputs = tf.random.uniform((1, 100, embed_dim)) \n",
    "outputs = transformer_encoder(inputs, training=False)  # Use keyword argument for 'training' \n",
    "print(outputs.shape)  # Should print (1, 100, 128) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "The TransformerEncoder is composed of multiple TransformerBlock layers, implementing the encoding part of the Transformer architecture. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Build and Compile the Transformer model \n",
    "\n",
    "Integrate the Transformer Encoder into a complete model for sequential data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1899, 100, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">793,088</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12800</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,801</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m793,088\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12800\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │        \u001b[38;5;34m12,801\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the necessary parameters \n",
    "\n",
    "embed_dim = 128 \n",
    "num_heads = 8 \n",
    "ff_dim = 512 \n",
    "num_layers = 4 \n",
    "\n",
    "# Define the Transformer Encoder \n",
    "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim) \n",
    "\n",
    "# Build the model \n",
    "input_shape = (X.shape[1], X.shape[2]) \n",
    "inputs = tf.keras.Input(shape=input_shape) \n",
    "\n",
    "# Project the inputs to the embed_dim \n",
    "x = tf.keras.layers.Dense(embed_dim)(inputs) \n",
    "encoder_outputs = transformer_encoder(x) \n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "outputs = tf.keras.layers.Dense(1)(flatten) \n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "# Compile the model \n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "# Summary of the model \n",
    "model.summary() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The Transformer Encoder model defines the necessary parameters, flattens the output, and ends with a dense layer to produce the final output.  \n",
    "\n",
    "- The model is then compiled with the Adam optimizer and mean squared error loss. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Train the Transformer model \n",
    "\n",
    "Train the model on the prepared dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 1s/step - loss: 11.4848   \n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 985ms/step - loss: 0.2233 \n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 994ms/step - loss: 0.1977 \n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 984ms/step - loss: 0.1354 \n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 991ms/step - loss: 0.1631\n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - loss: 0.2406 \n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - loss: 0.1248    \n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - loss: 0.1389\n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - loss: 0.0900 \n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.1014 \n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - loss: 0.0905 \n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - loss: 0.0735 \n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - loss: 0.0780 \n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 983ms/step - loss: 0.1156 \n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 982ms/step - loss: 0.0539\n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - loss: 0.0508   \n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 998ms/step - loss: 0.0836\n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: 0.0472\n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - loss: 0.0540    \n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - loss: 0.0555    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f2859bb5d90>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "The model is trained on the normalized stock price data for 20 epochs with a batch size of 32. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Evaluate and Make Predictions \n",
    "\n",
    "Evaluate the model's performance and make predictions on the dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 296ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions \n",
    "predictions = model.predict(X) \n",
    "predictions = scaler.inverse_transform(predictions) \n",
    " \n",
    "\n",
    "# Plot the predictions \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.plot(data, label='True Data') \n",
    "plt.plot(np.arange(time_step, time_step + len(predictions)), predictions, label='Predictions') \n",
    "plt.xlabel('Time') \n",
    "plt.ylabel('Stock Price') \n",
    "plt.legend() \n",
    "plt.show() \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The model's predictions are transformed back to the original scale using the inverse transform of the scaler. \n",
    "\n",
    "- The true data and predictions are plotted to visualize the model's performance. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Exercises: \n",
    "\n",
    " ### Exercise 1: Add dropout to the Transformer model \n",
    "\n",
    " **Objective: Understand how to add dropout layers to the Transformer model to prevent overfitting.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Add a dropout layer after the Flatten layer in the model. \n",
    "\n",
    "- Set the dropout rate to 0.5. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - loss: 6.7482  \n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1000ms/step - loss: 1.3086\n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 989ms/step - loss: 0.7427\n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 993ms/step - loss: 0.2733 \n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - loss: 0.1197   \n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.0495 \n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.0363\n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - loss: 0.0277\n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.0208\n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 995ms/step - loss: 0.0322 \n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - loss: 0.0189 \n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 992ms/step - loss: 0.0193 \n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 988ms/step - loss: 0.0173\n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 993ms/step - loss: 0.0134\n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 990ms/step - loss: 0.0153\n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 992ms/step - loss: 0.0191 \n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 999ms/step - loss: 0.0132\n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 983ms/step - loss: 0.0100\n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 982ms/step - loss: 0.0107\n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 990ms/step - loss: 0.0130 \n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 286ms/step - loss: 0.0105\n",
      "Test loss: 0.010538843460381031\n"
     ]
    }
   ],
   "source": [
    "## Write your code here.\n",
    "from tensorflow.keras.layers import Dropout \n",
    "\n",
    "  \n",
    "\n",
    "# Add a dropout layer after the Flatten layer \n",
    "\n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "\n",
    "dropout = Dropout(0.5)(flatten) \n",
    "\n",
    "outputs = tf.keras.layers.Dense(1)(dropout) \n",
    "\n",
    "  \n",
    "\n",
    "# Build the model \n",
    "\n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "  \n",
    "\n",
    "# Compile the model \n",
    "\n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "  \n",
    "\n",
    "# Train the model \n",
    "\n",
    "model.fit(X, Y, epochs=20, batch_size=32) \n",
    "\n",
    "  \n",
    "\n",
    "# Evaluate the model \n",
    "\n",
    "loss = model.evaluate(X, Y) \n",
    "\n",
    "print(f'Test loss: {loss}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "from tensorflow.keras.layers import Dropout \n",
    "\n",
    "  \n",
    "\n",
    "# Add a dropout layer after the Flatten layer \n",
    "\n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "\n",
    "dropout = Dropout(0.5)(flatten) \n",
    "\n",
    "outputs = tf.keras.layers.Dense(1)(dropout) \n",
    "\n",
    "  \n",
    "\n",
    "# Build the model \n",
    "\n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "  \n",
    "\n",
    "# Compile the model \n",
    "\n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "  \n",
    "\n",
    "# Train the model \n",
    "\n",
    "model.fit(X, Y, epochs=20, batch_size=32) \n",
    "\n",
    "  \n",
    "\n",
    "# Evaluate the model \n",
    "\n",
    "loss = model.evaluate(X, Y) \n",
    "\n",
    "print(f'Test loss: {loss}') \n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Experiment with different batch sizes \n",
    "\n",
    "**Objective: Observe the impact of different batch sizes on model performance.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Train the model with a batch size of 16. \n",
    "\n",
    "- Train the model with a batch size of 64. \n",
    "\n",
    "- Compare the training time and performance. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 589ms/step - loss: 0.0288 \n",
      "Epoch 2/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 584ms/step - loss: 0.0281 \n",
      "Epoch 3/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 584ms/step - loss: 0.0392 \n",
      "Epoch 4/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 588ms/step - loss: 0.0285 \n",
      "Epoch 5/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 582ms/step - loss: 0.0232 \n",
      "Epoch 6/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 582ms/step - loss: 0.0240 \n",
      "Epoch 7/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 588ms/step - loss: 0.0236 \n",
      "Epoch 8/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 585ms/step - loss: 0.0191 \n",
      "Epoch 9/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 585ms/step - loss: 0.0202 \n",
      "Epoch 10/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 583ms/step - loss: 0.0257 \n",
      "Epoch 11/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 577ms/step - loss: 0.0246 \n",
      "Epoch 12/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 581ms/step - loss: 0.0230 \n",
      "Epoch 13/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 583ms/step - loss: 0.0131 \n",
      "Epoch 14/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 587ms/step - loss: 0.0119 \n",
      "Epoch 15/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 581ms/step - loss: 0.0173 \n",
      "Epoch 16/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 582ms/step - loss: 0.0141 \n",
      "Epoch 17/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 586ms/step - loss: 0.0156 \n",
      "Epoch 18/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 585ms/step - loss: 0.0204 \n",
      "Epoch 19/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 582ms/step - loss: 0.0187 \n",
      "Epoch 20/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 585ms/step - loss: 0.0187 \n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 292ms/step - loss: 0.0046\n",
      "Test loss with batch size 16: 0.004725215956568718\n",
      "Epoch 1/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 0.0137\n",
      "Epoch 2/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - loss: 0.0051\n",
      "Epoch 3/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 0.0043\n",
      "Epoch 4/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 0.0040\n",
      "Epoch 5/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 2s/step - loss: 0.0038\n",
      "Epoch 6/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 0.0031\n",
      "Epoch 7/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 0.0038\n",
      "Epoch 8/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 0.0031\n",
      "Epoch 9/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 0.0031\n",
      "Epoch 10/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 0.0036\n",
      "Epoch 11/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 0.0037\n",
      "Epoch 12/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 0.0032\n",
      "Epoch 13/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 0.0032\n",
      "Epoch 14/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 2s/step - loss: 0.0026\n",
      "Epoch 15/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 0.0026\n",
      "Epoch 16/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 0.0035\n",
      "Epoch 17/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 0.0033\n",
      "Epoch 18/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - loss: 0.0033\n",
      "Epoch 19/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 0.0032\n",
      "Epoch 20/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 0.0037\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 290ms/step - loss: 4.8091e-04\n"
     ]
    }
   ],
   "source": [
    "## Write your code here.\n",
    "# Train the model with batch size 16\n",
    "model.fit(X, Y, epochs=20, batch_size=16)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 16: {loss}')\n",
    "\n",
    "# Train the model with batch size 64\n",
    "model.fit(X, Y, epochs=20, batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "# Train the model with batch size 16\n",
    "model.fit(X, Y, epochs=20, batch_size=16)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 16: {loss}')\n",
    "\n",
    "# Train the model with batch size 64\n",
    "model.fit(X, Y, epochs=20, batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 64: {loss}')\n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Use a different activation function \n",
    "\n",
    " **Objective: Understand how different activation functions impact the model performance.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Change the activation function of the Dense layer to `tanh`. \n",
    "\n",
    "- Train and evaluate the model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 1s/step - loss: 0.1799\n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - loss: 0.0199   \n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - loss: 0.0081\n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - loss: 0.0055   \n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - loss: 0.0058   \n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - loss: 0.0029   \n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - loss: 0.0041    \n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 998ms/step - loss: 0.0033\n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 991ms/step - loss: 0.0030 \n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - loss: 0.0046   \n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.0022   \n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - loss: 0.0035 \n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 994ms/step - loss: 0.0084 \n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1000ms/step - loss: 0.0024\n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 991ms/step - loss: 0.0049 \n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 990ms/step - loss: 0.0049\n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 979ms/step - loss: 0.0025 \n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 982ms/step - loss: 0.0037\n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 981ms/step - loss: 0.0029\n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 979ms/step - loss: 0.0106\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 287ms/step - loss: 0.0016\n",
      "Test loss with tanh activation: 0.0012040568981319666\n"
     ]
    }
   ],
   "source": [
    "## Write your code here.\n",
    "# Change the activation function of the Dense layer to tanh\n",
    "outputs = tf.keras.layers.Dense(1, activation='tanh')(flatten)\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with tanh activation: {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "# Change the activation function of the Dense layer to tanh\n",
    "outputs = tf.keras.layers.Dense(1, activation='tanh')(flatten)\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with tanh activation: {loss}')\n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Congratulations on completing this lab! In this lab, you have built an advanced Transformer model using Keras and applied it to a time series forecasting task. You have learned how to define and implement multi-head self-attention, Transformer blocks, encoder layers, and integrate them into a complete Transformer model. By experimenting with different configurations and training the model, you can further improve its performance and apply it to various sequential data tasks. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "28ac4fd81c1d713f83dcd1cdf1d3383ad25ea92873288fe9e978e9a17b314709"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
